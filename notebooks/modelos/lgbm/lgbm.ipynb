{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa46c2a0",
   "metadata": {},
   "source": [
    "Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3c24cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PWC-Challenge\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pred_lgbm as pred\n",
    "import funciones_lgbm as f_lgbm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ce3e4d",
   "metadata": {},
   "source": [
    "Entrenamos con una optimizaci√≥n de hiperpar√°metros utilizando optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07d30ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_lgbm_optuna(data, test_size=0.2, random_state=42, n_trials=100, timeout=300):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        data: DataFrame completo con todas las columnas (incluyendo Salary)\n",
    "        test_size: Proporci√≥n del conjunto de prueba\n",
    "        random_state: Semilla aleatoria\n",
    "        n_trials: N√∫mero m√°ximo de pruebas de Optuna\n",
    "        timeout: Tiempo l√≠mite en segundos para la optimizaci√≥n\n",
    "    \"\"\"\n",
    "    print(f\"\\nüöÄ Entrenando modelo LightGBM con Optuna + Features Estad√≠sticos\")\n",
    "    print(f\"   Trials: {n_trials}, Timeout: {timeout}s\")\n",
    "    \n",
    "    # Importaciones necesarias\n",
    "    from sklearn.model_selection import train_test_split, cross_val_score\n",
    "    from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "    import lightgbm as lgb\n",
    "    import optuna\n",
    "    import numpy as np\n",
    "    import warnings\n",
    "    \n",
    "    # Silenciar warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "    \n",
    "    # ============= PASO 1: PREPARAR GROUPING INFO =============\n",
    "    print(\"üìä Paso 1: Preparando informaci√≥n de agrupaci√≥n...\")\n",
    "    data_with_groups, grouping_info = f_lgbm.create_and_save_grouping_info(data)\n",
    "    all_job_cats, all_seniority_cats = f_lgbm.get_all_categories(data_with_groups)\n",
    "    \n",
    "    print(f\"   ‚úÖ Grupos creados: Age_group, Exp_group\")\n",
    "    print(f\"   ‚úÖ Job categories: {len(all_job_cats)}\")\n",
    "    print(f\"   ‚úÖ Seniority levels: {len(all_seniority_cats)}\")\n",
    "    \n",
    "    # ============= PASO 2: SEPARAR TARGET Y FEATURES =============\n",
    "    \n",
    "    print(\"üîÑ Paso 2: Separando target y features...\")\n",
    "    \n",
    "    X_data = data_with_groups.drop('Salary', axis=1)  # Variables disponibles en producci√≥n\n",
    "    y = data_with_groups['Salary']  # Target\n",
    "    \n",
    "    print(f\"   üìä Datos originales: {X_data.shape}\")\n",
    "    print(f\"   üéØ Target: {len(y)} registros\")\n",
    "    \n",
    "    # ============= PASO 3: SPLIT PRINCIPAL TRAIN/TEST =============\n",
    "    print(\"‚úÇÔ∏è  Paso 3: Split principal train/test...\")\n",
    "    X_train_base, X_test_base, y_train, y_test = train_test_split(\n",
    "        X_data, y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    print(f\"   üìà Train: {X_train_base.shape[0]} registros\")\n",
    "    print(f\"   üìâ Test:  {X_test_base.shape[0]} registros\")\n",
    "    \n",
    "    # ============= PASO 4: CREAR FEATURES CON ESTAD√çSTICAS =============\n",
    "    print(\"üîß Paso 4: Creando features con estad√≠sticas...\")\n",
    "    \n",
    "    # Crear features en TRAIN (calcula estad√≠sticas)\n",
    "    X_train, feature_names, stats_dict = f_lgbm.create_features_with_stats(\n",
    "        X_train_base,\n",
    "        all_job_categories=all_job_cats,\n",
    "        all_seniority_levels=all_seniority_cats,\n",
    "        stats_dict=None,\n",
    "        is_training=True\n",
    "    )\n",
    "    \n",
    "    # Aplicar features a TEST (usa estad√≠sticas de train)\n",
    "    X_test, _ = f_lgbm.create_features_with_stats(\n",
    "        X_test_base,\n",
    "        all_job_categories=all_job_cats,\n",
    "        all_seniority_levels=all_seniority_cats,\n",
    "        stats_dict=stats_dict,\n",
    "        is_training=False\n",
    "    )\n",
    "    \n",
    "    print(f\"   ‚úÖ Features totales: {X_train.shape[1]}\")\n",
    "    print(f\"   ‚úÖ Train: {X_train.shape}\")\n",
    "    print(f\"   ‚úÖ Test:  {X_test.shape}\")\n",
    "    \n",
    "    # ============= PASO 5: SPLIT PARA VALIDACI√ìN DE OPTUNA =============\n",
    "    print(\"üîÑ Paso 5: Split para validaci√≥n de Optuna...\")\n",
    "    X_train_opt, X_val_opt, y_train_opt, y_val_opt = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    print(f\"   üéØ Train opt: {X_train_opt.shape}\")\n",
    "    print(f\"   üîç Validation: {X_val_opt.shape}\")\n",
    "    \n",
    "    # ============= PASO 6: f_lgbmCI√ìN OBJETIVO PARA OPTUNA =============\n",
    "    def objective(trial):\n",
    "        \"\"\"f_lgbmci√≥n objetivo para Optuna\"\"\"\n",
    "        \n",
    "        # Hiperpar√°metros a optimizar\n",
    "        params = {\n",
    "            'objective': 'regression',\n",
    "            'metric': 'rmse',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'verbosity': -1,\n",
    "            'random_state': random_state,\n",
    "            'n_jobs': -1,\n",
    "            \n",
    "            # Par√°metros a optimizar\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 10, 300),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "            'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n",
    "            'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),\n",
    "            'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "            'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "            'min_child_weight': trial.suggest_float('min_child_weight', 0.001, 10.0, log=True),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 10.0),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 10.0),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 2000)\n",
    "        }\n",
    "        \n",
    "        # Crear y entrenar modelo\n",
    "        model = lgb.LGBMRegressor(**params)\n",
    "        \n",
    "        try:\n",
    "            # Entrenar con early stopping\n",
    "            model.fit(\n",
    "                X_train_opt, y_train_opt,\n",
    "                eval_set=[(X_val_opt, y_val_opt)],\n",
    "                callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)]\n",
    "            )\n",
    "            \n",
    "            # Predecir en conjunto de validaci√≥n\n",
    "            y_pred = model.predict(X_val_opt)\n",
    "            rmse = np.sqrt(mean_squared_error(y_val_opt, y_pred))\n",
    "            \n",
    "            return rmse\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Si hay error, devolver un valor alto\n",
    "            return float('inf')\n",
    "    \n",
    "    # ============= PASO 7: OPTIMIZACI√ìN CON OPTUNA =============\n",
    "    print(\"üéØ Paso 7: Optimizando hiperpar√°metros con Optuna...\")\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=random_state))\n",
    "    \n",
    "    # Optimizar\n",
    "    study.optimize(objective, n_trials=n_trials, timeout=timeout, show_progress_bar=True)\n",
    "    \n",
    "    print(f\"   ‚úÖ Optimizaci√≥n completada: {len(study.trials)} trials realizados\")\n",
    "    print(f\"   üèÜ Mejor RMSE de validaci√≥n: ${study.best_value:,.2f}\")\n",
    "    \n",
    "    # ============= PASO 8: MODELO FINAL =============\n",
    "    print(\"üèÜ Paso 8: Entrenando modelo final...\")\n",
    "    \n",
    "    # Obtener mejores par√°metros\n",
    "    best_params = study.best_params.copy()\n",
    "    best_params.update({\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'verbosity': -1,\n",
    "        'random_state': random_state,\n",
    "        'n_jobs': -1\n",
    "    })\n",
    "    \n",
    "    print(\"   üìã Mejores hiperpar√°metros encontrados:\")\n",
    "    for param, value in best_params.items():\n",
    "        if param not in ['objective', 'metric', 'boosting_type', 'verbosity', 'random_state', 'n_jobs']:\n",
    "            print(f\"      {param}: {value}\")\n",
    "    \n",
    "    # Entrenar modelo final con mejores par√°metros\n",
    "    final_model = lgb.LGBMRegressor(**best_params)\n",
    "    \n",
    "    try:\n",
    "        # Entrenar en todo el conjunto de entrenamiento\n",
    "        final_model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_test, y_test)],\n",
    "            callbacks=[lgb.early_stopping(stopping_rounds=100, verbose=False)]\n",
    "        )\n",
    "        \n",
    "        # ============= PASO 9: EVALUACI√ìN FINAL =============\n",
    "        print(\"üìä Paso 9: Evaluaci√≥n final...\")\n",
    "        \n",
    "        # Predicciones finales\n",
    "        y_pred = final_model.predict(X_test)\n",
    "        \n",
    "        # M√©tricas en conjunto de prueba\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        \n",
    "        # Cross-validation con el modelo optimizado\n",
    "        print(\"   üîÑ Realizando validaci√≥n cruzada final...\")\n",
    "        cv_model = lgb.LGBMRegressor(**best_params)\n",
    "        cv_scores = cross_val_score(\n",
    "            cv_model, X_train, y_train, cv=5, \n",
    "            scoring='neg_mean_squared_error', n_jobs=-1\n",
    "        )\n",
    "        cv_rmse = np.sqrt(-cv_scores.mean())\n",
    "        cv_std = np.sqrt(cv_scores.std())\n",
    "        \n",
    "        # ============= PASO 10: PREPARAR RESULTADOS =============\n",
    "        print(\"üì¶ Paso 10: Preparando resultados finales...\")\n",
    "        \n",
    "        # Resultados del modelo\n",
    "        model_metrics = {\n",
    "            'model': final_model,\n",
    "            'rmse': rmse,\n",
    "            'r2': r2,\n",
    "            'mae': mae,\n",
    "            'cv_rmse': cv_rmse,\n",
    "            'cv_std': cv_std,\n",
    "            'predictions': y_pred,\n",
    "            'feature_importances': final_model.feature_importances_,\n",
    "            'n_estimators_used': final_model.best_iteration_ if hasattr(final_model, 'best_iteration_') else final_model.n_estimators,\n",
    "            'best_params': best_params,\n",
    "            'optuna_study': study\n",
    "        }\n",
    "        \n",
    "        # Resultado completo para compatibilidad\n",
    "        final_results = {\n",
    "            'model_results': {'LightGBM_Optuna': model_metrics},\n",
    "            'best_model_name': 'LightGBM_Optuna',\n",
    "            'best_model': final_model,\n",
    "            'feature_names': feature_names,\n",
    "            'job_categories': all_job_cats,\n",
    "            'seniority_categories': all_seniority_cats,\n",
    "            'stats_dict': stats_dict,\n",
    "            'grouping_info': grouping_info,\n",
    "            'X_test': X_test,\n",
    "            'y_test': y_test,\n",
    "            'X_train': X_train,\n",
    "            'y_train': y_train,\n",
    "            'optimization_study': study\n",
    "        }\n",
    "        \n",
    "        # ============= MOSTRAR RESULTADOS =============\n",
    "        print(f\"\\nüéâ RESULTADOS FINALES:\")\n",
    "        print(f\"   RMSE: ${rmse:,.2f}\")\n",
    "        print(f\"   R¬≤: {r2:.3f}\")\n",
    "        print(f\"   MAE: ${mae:,.2f}\")\n",
    "        print(f\"   CV RMSE: ${cv_rmse:,.2f} (¬±{cv_std:,.2f})\")\n",
    "        print(f\"   Features totales: {len(feature_names)}\")\n",
    "        print(f\"   Estimadores utilizados: {model_metrics['n_estimators_used']}\")\n",
    "        print(f\"   Mejora vs RMSE de validaci√≥n: {((study.best_value - rmse) / study.best_value * 100):+.2f}%\")\n",
    "        \n",
    "        return final_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error entrenando modelo final: {str(e)}\")\n",
    "        import traceback\n",
    "        print(traceback.format_exc())\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db5a880",
   "metadata": {},
   "source": [
    "PIPELINE - LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cacc2417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ INICIANDO PIPELINE\n",
      "\n",
      "üöÄ Entrenando modelo LightGBM con Optuna + Features Estad√≠sticos\n",
      "   Trials: 100, Timeout: 300s\n",
      "üìä Paso 1: Preparando informaci√≥n de agrupaci√≥n...\n",
      "üìä Creando grupos y guardando informaci√≥n de rangos...\n",
      "   ‚úÖ Grupos creados: Age_group, Exp_group\n",
      "   ‚úÖ Job categories: 12\n",
      "   ‚úÖ Seniority levels: 5\n",
      "üîÑ Paso 2: Separando target y features...\n",
      "   üìä Datos originales: (369, 9)\n",
      "   üéØ Target: 369 registros\n",
      "‚úÇÔ∏è  Paso 3: Split principal train/test...\n",
      "   üìà Train: 295 registros\n",
      "   üìâ Test:  74 registros\n",
      "üîß Paso 4: Creando features con estad√≠sticas...\n",
      "üîß Creando caracter√≠sticas completas para producci√≥n (originales + estad√≠sticos)...\n",
      "üîß Creando todas las caracter√≠sticas mejoradas...\n",
      "‚úÖ Creadas 61 caracter√≠sticas en total\n",
      "   - Variables num√©ricas b√°sicas: 3\n",
      "   - Variables de educaci√≥n: 3\n",
      "   - Variables de job category: 12\n",
      "   - Variables de seniority: 6\n",
      "   - Variables de texto: 4\n",
      "   - Ratios y scores: 5\n",
      "üìä Creando features estad√≠sticos para producci√≥n (TRAIN)...\n",
      "   üîÑ Calculando estad√≠sticas en TRAIN (solo variables de producci√≥n)...\n",
      "   ‚úÖ Estad√≠sticas calculadas para 7 grupos\n",
      "   ‚úÖ Creadas 32 features estad√≠sticos para producci√≥n\n",
      "‚úÖ Features totales para producci√≥n: 93\n",
      "   - Originales: 61\n",
      "   - Estad√≠sticos: 32\n",
      "   ‚úÖ Todas las features son seguras para producci√≥n (sin target leakage)\n",
      "üîß Creando caracter√≠sticas completas para producci√≥n (originales + estad√≠sticos)...\n",
      "üîß Creando todas las caracter√≠sticas mejoradas...\n",
      "‚úÖ Creadas 61 caracter√≠sticas en total\n",
      "   - Variables num√©ricas b√°sicas: 3\n",
      "   - Variables de educaci√≥n: 3\n",
      "   - Variables de job category: 12\n",
      "   - Variables de seniority: 6\n",
      "   - Variables de texto: 4\n",
      "   - Ratios y scores: 5\n",
      "üìä Creando features estad√≠sticos para producci√≥n (PREDICT)...\n",
      "   üì• Usando estad√≠sticas pre-calculadas de TRAIN...\n",
      "   ‚úÖ Creadas 32 features estad√≠sticos para producci√≥n\n",
      "‚úÖ Features totales para producci√≥n: 93\n",
      "   - Originales: 61\n",
      "   - Estad√≠sticos: 32\n",
      "   ‚úÖ Todas las features son seguras para producci√≥n (sin target leakage)\n",
      "   ‚úÖ Features totales: 93\n",
      "   ‚úÖ Train: (295, 93)\n",
      "   ‚úÖ Test:  (74, 93)\n",
      "üîÑ Paso 5: Split para validaci√≥n de Optuna...\n",
      "   üéØ Train opt: (236, 93)\n",
      "   üîç Validation: (59, 93)\n",
      "üéØ Paso 7: Optimizando hiperpar√°metros con Optuna...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 88. Best value: 13311.5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:10<00:00,  9.35it/s, 10.69/300 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Optimizaci√≥n completada: 100 trials realizados\n",
      "   üèÜ Mejor RMSE de validaci√≥n: $13,311.46\n",
      "üèÜ Paso 8: Entrenando modelo final...\n",
      "   üìã Mejores hiperpar√°metros encontrados:\n",
      "      num_leaves: 21\n",
      "      learning_rate: 0.1103186092201265\n",
      "      feature_fraction: 0.906524091469967\n",
      "      bagging_fraction: 0.6815973162203444\n",
      "      bagging_freq: 1\n",
      "      min_child_samples: 23\n",
      "      min_child_weight: 0.7585553500711019\n",
      "      reg_alpha: 9.248611683528368\n",
      "      reg_lambda: 1.5875177712326718\n",
      "      max_depth: 13\n",
      "      n_estimators: 803\n",
      "üìä Paso 9: Evaluaci√≥n final...\n",
      "   üîÑ Realizando validaci√≥n cruzada final...\n",
      "üì¶ Paso 10: Preparando resultados finales...\n",
      "\n",
      "üéâ RESULTADOS FINALES:\n",
      "   RMSE: $16,963.52\n",
      "   R¬≤: 0.886\n",
      "   MAE: $9,915.00\n",
      "   CV RMSE: $11,777.75 (¬±6,188.65)\n",
      "   Features totales: 93\n",
      "   Estimadores utilizados: 134\n",
      "   Mejora vs RMSE de validaci√≥n: -27.44%\n",
      "üî¨ An√°lisis de optimizaci√≥n Optuna:\n",
      "   N√∫mero total de trials: 100\n",
      "   Mejor valor: $13,311.46\n",
      "   Trials completados: 100\n",
      "   Trials fallidos: 0\n",
      "   üîç Importancia de hiperpar√°metros (Top 10):\n",
      "       1. min_child_samples    - 0.8232\n",
      "       2. learning_rate        - 0.1304\n",
      "       3. num_leaves           - 0.0113\n",
      "       4. bagging_fraction     - 0.0104\n",
      "       5. feature_fraction     - 0.0089\n",
      "       6. max_depth            - 0.0052\n",
      "       7. reg_lambda           - 0.0037\n",
      "       8. reg_alpha            - 0.0030\n",
      "       9. n_estimators         - 0.0016\n",
      "      10. min_child_weight     - 0.0013\n",
      "\n",
      "üéâ AN√ÅLISIS COMPLETADO!\n",
      "==================================================\n",
      "\n",
      "üèÜ RESUMEN FINAL:\n",
      "   Mejor modelo: LightGBM_Optuna\n",
      "   RMSE: $16,963.52\n",
      "   R¬≤: 0.886\n",
      "   CV RMSE: $11,777.75\n"
     ]
    }
   ],
   "source": [
    "def pipeline_fe():\n",
    "    print(\"üöÄ INICIANDO PIPELINE\")\n",
    "\n",
    "    # 1 . Cargar datos\n",
    "    data = pd.read_csv('../../../dataC/imputado.csv')\n",
    "    data[\"Description\"] = data[\"Description\"].fillna(\"\")\n",
    "    \n",
    "    data = data.dropna()\n",
    "    # Se mejora levemente los errores realizando esta imputaci√≥n y dejando los otros nulos de los otros features.\n",
    "    \n",
    "    # Entrenar modelo\n",
    "    model_results =train_model_lgbm_optuna(data)\n",
    "\n",
    "    # Analizar optimizaci√≥n\n",
    "    best_params, best_value = f_lgbm.analyze_optuna_optimization(model_results['optimization_study'])\n",
    "\n",
    "    # Visualizar proceso\n",
    "    #plot_optuna_optimization(model_results['optimization_study'])\n",
    "\n",
    "    # 5. Analizar importancia\n",
    "    #feature_importance = fun.analyze_feature_importance(X,feature_names,model)\n",
    "\n",
    "    # 6. Analizar predicciones\n",
    "    #predictions_analysis = f.analyze_predictions(model_results)\n",
    "\n",
    "    # 7. Comparar modelos\n",
    "    #fun.create_comparison_chart(model_results)\n",
    "\n",
    "    print(\"\\nüéâ AN√ÅLISIS COMPLETADO!\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # Resumen final\n",
    "    best_name = model_results['best_model_name']\n",
    "    best_result = model_results['model_results'][best_name]\n",
    "\n",
    "    print(f\"\\nüèÜ RESUMEN FINAL:\")\n",
    "    print(f\"   Mejor modelo: {best_name}\")\n",
    "    print(f\"   RMSE: ${best_result['rmse']:,.2f}\")\n",
    "    print(f\"   R¬≤: {best_result['r2']:.3f}\")\n",
    "    print(f\"   CV RMSE: ${best_result['cv_rmse']:,.2f}\")\n",
    "    #print(f\"   Caracter√≠sticas utilizadas: {len(feature_names)}\")\n",
    "    \n",
    "    \n",
    "\n",
    "     \n",
    "    return model_results,data\n",
    "    # ,model,X,feature_importance\n",
    "    \n",
    "results,data=pipeline_fe()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73ac5233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Guardando modelo completo con features estad√≠sticos...\n",
      "‚úÖ Modelo completo guardado en ../../../modelos/salary_with_stats.pkl\n",
      "üì¶ Incluye:\n",
      "   ü§ñ Modelo LightGBM optimizado\n",
      "   üî¢ 93 caracter√≠sticas\n",
      "   üìä Features estad√≠sticos (stats_dict)\n",
      "   üè∑Ô∏è  12 categor√≠as de trabajo\n",
      "   üëî 5 niveles de seniority\n",
      "   üìà Informaci√≥n de agrupaci√≥n\n",
      "   üìâ M√©tricas del modelo\n"
     ]
    }
   ],
   "source": [
    "complete_package = f_lgbm.save_with_stats(\n",
    "        results,\n",
    "        filename=\"../../../modelos/salary_with_stats.pkl\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef330786",
   "metadata": {},
   "source": [
    "Probamos con  una nueva predicci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab63f570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b88d4a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package = joblib.load(\"../../../modelos/salary_with_stats.pkl\")\n",
    "def test_prediction(model_package):\n",
    "    \"\"\"\n",
    "    Test para verificar que la predicci√≥n funciona con un solo registro\n",
    "    \"\"\"\n",
    "    print(\"üß™ Testing predicci√≥n con un solo registro...\")\n",
    "    \n",
    "    # Crear registro de prueba\n",
    "    exp_group, age_group = pred.calculate_groups(\n",
    "    age=60, \n",
    "    years_of_experience=24, \n",
    "    grouping_info=model_package.get('grouping_info')\n",
    "    )\n",
    "\n",
    "    test_record = pd.DataFrame({\n",
    "    'Age': [60],\n",
    "    'Gender': ['Male'],\n",
    "    'Education_Level': [\"PhD\"],\n",
    "    'Job_Title': ['CEO'],\n",
    "    'Years_of_Experience': [24],\n",
    "    'Description': ['I work with machine learning models and data analysis'],\n",
    "    'Exp_group': [exp_group],      # ‚Üê Calculado autom√°ticamente\n",
    "    'Age_group': [age_group]       # ‚Üê Calculado autom√°ticamente\n",
    "    })\n",
    "    \n",
    "    try:\n",
    "        prediction = pred.predict(test_record, model_package)\n",
    "        print(f\"‚úÖ Test exitoso: Predicci√≥n = ${prediction:,.2f}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Test fall√≥: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d58ae55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "model_package = joblib.load(\"../../../modelos/salary_with_stats.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386cbe63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing predicci√≥n con un solo registro...\n",
      "üéØ Predicci√≥n con modelo completo (un solo registro)...\n",
      "   üî¢ Features esperadas: 93\n",
      "üîß Creando caracter√≠sticas completas para un solo registro...\n",
      "üîß Creando todas las caracter√≠sticas mejoradas...\n",
      "‚úÖ Creadas 61 caracter√≠sticas en total\n",
      "   - Variables num√©ricas b√°sicas: 3\n",
      "   - Variables de educaci√≥n: 3\n",
      "   - Variables de job category: 12\n",
      "   - Variables de seniority: 6\n",
      "   - Variables de texto: 4\n",
      "   - Ratios y scores: 5\n",
      "üìä Creando features estad√≠sticos para un solo registro...\n",
      "   ‚úÖ Creadas 32 features estad√≠sticos para un solo registro\n",
      "‚úÖ Features totales para un solo registro: 93\n",
      "   - Originales: 61\n",
      "   - Estad√≠sticos: 32\n",
      "   üî¢ Features generadas: 93\n",
      "   üí∞ Predicci√≥n: $172,229.38\n",
      "   ‚úÖ Predicci√≥n exitosa con 93 features\n",
      "‚úÖ Test exitoso: Predicci√≥n = $172,229.38\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prediction(model_package)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ce234e",
   "metadata": {},
   "source": [
    "An√°lisis de la optimizaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c40525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç AN√ÅLISIS DE IMPORTANCIA DE HIPERPAR√ÅMETROS\n",
      "==================================================\n",
      "üî¨ An√°lisis de optimizaci√≥n Optuna:\n",
      "   N√∫mero total de trials: 100\n",
      "   Mejor valor: $13,311.46\n",
      "   Trials completados: 100\n",
      "   Trials fallidos: 0\n",
      "   üîç Importancia de hiperpar√°metros (Top 10):\n",
      "       1. min_child_samples    - 0.8167\n",
      "       2. learning_rate        - 0.1355\n",
      "       3. num_leaves           - 0.0151\n",
      "       4. feature_fraction     - 0.0094\n",
      "       5. reg_lambda           - 0.0074\n",
      "       6. bagging_fraction     - 0.0059\n",
      "       7. reg_alpha            - 0.0034\n",
      "       8. max_depth            - 0.0031\n",
      "       9. n_estimators         - 0.0027\n",
      "      10. min_child_weight     - 0.0004\n",
      "\n",
      "üìä M√âTRICAS FINALES DEL MODELO OPTIMIZADO\n",
      "==================================================\n",
      "üéØ RMSE en Test: $16,963.52\n",
      "üìà R¬≤ Score: 0.8859 (88.59%)\n",
      "üìâ MAE: $9,915.00\n",
      "üîÑ CV RMSE: $11,777.75 (¬±6,188.65)\n",
      "üå≥ Estimadores usados: 134\n",
      "‚ö° Mejora total: -34.63% respecto al inicio\n",
      "\n",
      "üîç IMPORTANCIA DE CARACTER√çSTICAS\n",
      "==================================================\n",
      "\n",
      "üîç Top 20 caracter√≠sticas m√°s importantes:\n",
      "    1. avg_word_length      - 59.0000\n",
      "    2. description_length_zscore - 51.0000\n",
      "    3. age_vs_job_cat_mean  - 44.0000\n",
      "    4. age_edu              - 39.0000\n",
      "    5. exp_consistency_score - 34.0000\n",
      "    6. word_count           - 33.0000\n",
      "    7. age_experience_ratio - 31.0000\n",
      "    8. age_consistency_score - 30.0000\n",
      "    9. exp_vs_job_cat_mean  - 28.0000\n",
      "   10. exp_edu              - 25.0000\n",
      "   11. leadership_terms_count - 22.0000\n",
      "   12. exp_vs_age_group_mean - 19.0000\n",
      "   13. age_vs_gender_mean   - 19.0000\n",
      "   14. age_exp_interaction  - 18.0000\n",
      "   15. experience_age_ratio - 17.0000\n",
      "   16. gender_male          - 16.0000\n",
      "   17. age_vs_exp_group_mean - 15.0000\n",
      "   18. leadership_potential - 15.0000\n",
      "   19. age_vs_edu_mean      - 14.0000\n",
      "   20. seniority_experience_ratio - 14.0000\n",
      "\n",
      "üéØ AN√ÅLISIS DE CALIDAD DE PREDICCIONES\n",
      "==================================================\n",
      "Media de residuos: $2,309.95\n",
      "Std de residuos: $16,805.51\n",
      "Mediana abs residuos: $6,465.30\n",
      "\n",
      "Percentiles de error absoluto:\n",
      "  25%: $2,862.55\n",
      "  50%: $6,465.30\n",
      "  75%: $13,579.93\n",
      "  95%: $25,112.87\n",
      "\n",
      "üîç AN√ÅLISIS DE OUTLIERS\n",
      "==================================================\n",
      "Outliers detectados: 3 (4.05%)\n",
      "Threshold usado: $27,528.46\n",
      "Error promedio en outliers: $57,736.66\n",
      "Valor real promedio outliers: $166,666.67\n",
      "\n",
      "‚öôÔ∏è HIPERPAR√ÅMETROS √ìPTIMOS ENCONTRADOS\n",
      "==================================================\n",
      "num_leaves          : 21\n",
      "learning_rate       : 0.1103186092201265\n",
      "max_depth           : 13\n",
      "n_estimators        : 803\n",
      "feature_fraction    : 0.906524091469967\n",
      "bagging_fraction    : 0.6815973162203444\n",
      "reg_alpha           : 9.248611683528368\n",
      "reg_lambda          : 1.5875177712326718\n",
      "\n",
      "üìà COMPARACI√ìN CON CONFIGURACI√ìN BASE\n",
      "==================================================\n",
      "Par√°metro             Base      Optimizado    Cambio\n",
      "-------------------------------------------------------\n",
      "num_leaves                 31          21        -10\n",
      "learning_rate           0.100       0.110     +10.3%\n",
      "max_depth                  -1          13        +14\n",
      "n_estimators              100         803       +703\n",
      "feature_fraction        1.000       0.907      -9.3%\n",
      "bagging_fraction        1.000       0.682     -31.8%\n",
      "\n",
      "üí° RECOMENDACIONES Y CONCLUSIONES\n",
      "==================================================\n",
      "‚úÖ Aspectos positivos:\n",
      "  ‚Ä¢ Convergencia estable alcanzada en ~45 trials\n",
      "  ‚Ä¢ Mejora significativa: -34.6% en RMSE\n",
      "  ‚Ä¢ R¬≤ de 0.886 indica buen ajuste\n",
      "  ‚Ä¢ CV estable con baja varianza\n",
      "  ‚Ä¢ Excelente capacidad predictiva (R¬≤ > 0.8)\n",
      "\n",
      "‚ö†Ô∏è  √Åreas de atenci√≥n:\n",
      "  ‚Ä¢ Varianza en CV relativamente alta - validar estabilidad\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 1. AN√ÅLISIS DE IMPORTANCIA DE HIPERPAR√ÅMETROS\n",
    "print(\"üîç AN√ÅLISIS DE IMPORTANCIA DE HIPERPAR√ÅMETROS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Suponiendo que tienes tu study guardado en 'results' o 'study'\n",
    "best_params, best_value = f_lgbm.analyze_optuna_optimization(results['optimization_study'])\n",
    "\n",
    "# 2. AN√ÅLISIS DETALLADO DE M√âTRICAS FINALES\n",
    "print(\"\\nüìä M√âTRICAS FINALES DEL MODELO OPTIMIZADO\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "final_model = results['best_model']\n",
    "model_results = results['model_results']['LightGBM_Optuna']\n",
    "\n",
    "print(f\"üéØ RMSE en Test: ${model_results['rmse']:,.2f}\")\n",
    "print(f\"üìà R¬≤ Score: {model_results['r2']:.4f} ({model_results['r2']*100:.2f}%)\")\n",
    "print(f\"üìâ MAE: ${model_results['mae']:,.2f}\")\n",
    "print(f\"üîÑ CV RMSE: ${model_results['cv_rmse']:,.2f} (¬±{model_results['cv_std']:,.2f})\")\n",
    "print(f\"üå≥ Estimadores usados: {model_results['n_estimators_used']}\")\n",
    "\n",
    "# Calcular mejora respecto a baseline\n",
    "rmse_improvement = ((12600 - model_results['rmse']) / 12600) * 100\n",
    "print(f\"‚ö° Mejora total: {rmse_improvement:.2f}% respecto al inicio\")\n",
    "\n",
    "# 3. AN√ÅLISIS DE IMPORTANCIA DE CARACTER√çSTICAS\n",
    "print(\"\\nüîç IMPORTANCIA DE CARACTER√çSTICAS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "feature_importance_df = f_lgbm.get_feature_importance(\n",
    "    final_model, \n",
    "    feature_names=results.get('feature_names'), \n",
    "    top_n=20\n",
    ")\n",
    "\n",
    "# 4. AN√ÅLISIS DE CALIDAD DE PREDICCIONES\n",
    "print(\"\\nüéØ AN√ÅLISIS DE CALIDAD DE PREDICCIONES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "y_test = results['y_test']\n",
    "y_pred = model_results['predictions']\n",
    "residuos = y_test - y_pred\n",
    "\n",
    "# Estad√≠sticas de residuos\n",
    "print(f\"Media de residuos: ${np.mean(residuos):,.2f}\")\n",
    "print(f\"Std de residuos: ${np.std(residuos):,.2f}\")\n",
    "print(f\"Mediana abs residuos: ${np.median(np.abs(residuos)):,.2f}\")\n",
    "\n",
    "# Percentiles de error absoluto\n",
    "abs_errors = np.abs(residuos)\n",
    "print(f\"\\nPercentiles de error absoluto:\")\n",
    "print(f\"  25%: ${np.percentile(abs_errors, 25):,.2f}\")\n",
    "print(f\"  50%: ${np.percentile(abs_errors, 50):,.2f}\")\n",
    "print(f\"  75%: ${np.percentile(abs_errors, 75):,.2f}\")\n",
    "print(f\"  95%: ${np.percentile(abs_errors, 95):,.2f}\")\n",
    "\n",
    "# 5. AN√ÅLISIS DE OUTLIERS EN PREDICCIONES\n",
    "print(f\"\\nüîç AN√ÅLISIS DE OUTLIERS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Definir outliers como errores > 2 std\n",
    "threshold = 2 * np.std(abs_errors)\n",
    "outliers = abs_errors > threshold\n",
    "n_outliers = np.sum(outliers)\n",
    "outlier_pct = (n_outliers / len(abs_errors)) * 100\n",
    "\n",
    "print(f\"Outliers detectados: {n_outliers} ({outlier_pct:.2f}%)\")\n",
    "print(f\"Threshold usado: ${threshold:,.2f}\")\n",
    "\n",
    "if n_outliers > 0:\n",
    "    print(f\"Error promedio en outliers: ${np.mean(abs_errors[outliers]):,.2f}\")\n",
    "    print(f\"Valor real promedio outliers: ${np.mean(y_test[outliers]):,.2f}\")\n",
    "\n",
    "# 6. AN√ÅLISIS DE HIPERPAR√ÅMETROS √ìPTIMOS\n",
    "print(f\"\\n‚öôÔ∏è HIPERPAR√ÅMETROS √ìPTIMOS ENCONTRADOS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "important_params = [\n",
    "    'num_leaves', 'learning_rate', 'max_depth', 'n_estimators',\n",
    "    'feature_fraction', 'bagging_fraction', 'reg_alpha', 'reg_lambda'\n",
    "]\n",
    "\n",
    "for param in important_params:\n",
    "    if param in best_params:\n",
    "        print(f\"{param:20s}: {best_params[param]}\")\n",
    "\n",
    "# 7. COMPARACI√ìN CON CONFIGURACI√ìN BASE\n",
    "print(f\"\\nüìà COMPARACI√ìN CON CONFIGURACI√ìN BASE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Configuraci√≥n base t√≠pica\n",
    "base_config = {\n",
    "    'num_leaves': 31,  # Default\n",
    "    'learning_rate': 0.1,  # Default\n",
    "    'max_depth': -1,  # Default (sin l√≠mite)\n",
    "    'n_estimators': 100,  # Default\n",
    "    'feature_fraction': 1.0,  # Default\n",
    "    'bagging_fraction': 1.0,  # Default\n",
    "}\n",
    "\n",
    "print(\"Par√°metro             Base      Optimizado    Cambio\")\n",
    "print(\"-\" * 55)\n",
    "for param in important_params[:6]:  # Top 6 m√°s importantes\n",
    "    if param in best_params and param in base_config:\n",
    "        base_val = base_config[param]\n",
    "        opt_val = best_params[param]\n",
    "        if isinstance(opt_val, float):\n",
    "            change = f\"{((opt_val - base_val) / base_val * 100):+.1f}%\"\n",
    "            print(f\"{param:20s} {base_val:8.3f} {opt_val:11.3f} {change:>10s}\")\n",
    "        else:\n",
    "            change = f\"{opt_val - base_val:+d}\"\n",
    "            print(f\"{param:20s} {base_val:8d} {opt_val:11d} {change:>10s}\")\n",
    "\n",
    "# 8. RECOMENDACIONES FINALES\n",
    "print(f\"\\nüí° RECOMENDACIONES Y CONCLUSIONES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"‚úÖ Aspectos positivos:\")\n",
    "print(f\"  ‚Ä¢ Convergencia estable alcanzada en ~45 trials\")\n",
    "print(f\"  ‚Ä¢ Mejora significativa: {rmse_improvement:.1f}% en RMSE\")\n",
    "print(f\"  ‚Ä¢ R¬≤ de {model_results['r2']:.3f} indica buen ajuste\")\n",
    "print(f\"  ‚Ä¢ CV estable con baja varianza\")\n",
    "\n",
    "if model_results['r2'] > 0.8:\n",
    "    print(f\"  ‚Ä¢ Excelente capacidad predictiva (R¬≤ > 0.8)\")\n",
    "elif model_results['r2'] > 0.6:\n",
    "    print(f\"  ‚Ä¢ Buena capacidad predictiva (R¬≤ > 0.6)\")\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è  √Åreas de atenci√≥n:\")\n",
    "if outlier_pct > 5:\n",
    "    print(f\"  ‚Ä¢ {outlier_pct:.1f}% de outliers - considerar an√°lisis adicional\")\n",
    "if model_results['cv_std'] > model_results['cv_rmse'] * 0.1:\n",
    "    print(f\"  ‚Ä¢ Varianza en CV relativamente alta - validar estabilidad\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f85f5c",
   "metadata": {},
   "source": [
    "El 25% de los casos se predicen con un error menor a $1250 ok.\n",
    "\n",
    "El 50% (mediana) est√°n dentro de $6000 ok.\n",
    "\n",
    "Pero un 25% tiene errores mayores a $12.800, y un 5% supera los $24.500\n",
    "\n",
    "Salarios de aproximadamente $200 000 un error 12%\n",
    "\n",
    "Construir nuevas variables que puedan captar este comportamiento - work\n",
    "\n",
    "El modelo muestra un excelente rendimiento general, con m√©tricas s√≥lidas y comportamiento estable. Revisar casos extremos (outliers) y si hay segmentos que afectan la varianza de la validaci√≥n cruzada.\n",
    "\n",
    "Posible forma en la que se generan los grupos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dacdca4",
   "metadata": {},
   "source": [
    "Revisemos los outliers de predicci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab599a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç AN√ÅLISIS DE OUTLIERS CON MODEL_RESULTS\n",
      "============================================================\n",
      "üìä Datos disponibles:\n",
      "   ‚Ä¢ Predicciones: 74 casos\n",
      "   ‚Ä¢ Valores reales: 74 casos\n",
      "\n",
      "üéØ DETECCI√ìN DE OUTLIERS:\n",
      "   ‚Ä¢ Threshold: $27,528.46\n",
      "   ‚Ä¢ Outliers encontrados: 3 casos\n",
      "   ‚Ä¢ Porcentaje: 4.05%\n",
      "\n",
      "üî¥ TOP 15 OUTLIERS M√ÅS PROBLEM√ÅTICOS\n",
      "================================================================================\n",
      "Rank  Index   Salario Real   Predicci√≥n    Error Abs    Error %\n",
      "---------------------------------------------------------------------------\n",
      " 1      42   $   250000   $   141914   $  108086     43.2%\n",
      " 2      16   $    90000   $    54140   $   35860     39.8%\n",
      " 3       6   $   160000   $   130736   $   29264     18.3%\n",
      "\n",
      "üìà COMPARACI√ìN: OUTLIERS vs CASOS NORMALES\n",
      "============================================================\n",
      "M√©trica                 Outliers      Normales    Diferencia\n",
      "-----------------------------------------------------------------\n",
      "Media Salario          $   166667 $    95282   $   +71385\n",
      "Std Salario            $    65490 $    47329   $   +18160\n",
      "Error Promedio         $    57737 $     7894   $   +49842\n",
      "Error Mediano          $    35860 $     6170   $   +29689\n",
      "\n",
      "üìä DISTRIBUCI√ìN DE OUTLIERS POR RANGOS SALARIALES\n",
      "============================================================\n",
      "Rango Salarial        Total    Outliers   Tasa Outlier\n",
      "------------------------------------------------------------\n",
      "Bajo (<$50K)              16           0       0.00%\n",
      "Medio ($50K-$100K)        24           1       4.17%\n",
      "Alto ($100K-$150K)        19           0       0.00%\n",
      "Muy Alto ($150K-$200K)      14           1       7.14%\n",
      "Premium (>$200K)           1           1     100.00%\n",
      "\n",
      "üéØ PATRONES EN LAS PREDICCIONES ERR√ìNEAS\n",
      "============================================================\n",
      "üìâ Subestimaciones severas (>30%): 2 casos\n",
      "   ‚Ä¢ Error promedio: $71,973\n",
      "   ‚Ä¢ Salario real promedio: $170,000\n",
      "   ‚Ä¢ Predicci√≥n promedio: $98,027\n",
      "\n",
      "üìà Sobreestimaciones severas (>30%): 0 casos\n",
      "\n",
      "üîç CASOS EXTREMOS PARA INVESTIGACI√ìN\n",
      "============================================================\n",
      "‚ö†Ô∏è  Casos con error relativo >50%: 0\n",
      "\n",
      "üìä M√âTRICAS ESPEC√çFICAS DE OUTLIERS\n",
      "============================================================\n",
      "üéØ Estad√≠sticas de errores en outliers:\n",
      "   ‚Ä¢ Error absoluto promedio: $57,736.66\n",
      "   ‚Ä¢ Error absoluto mediano: $35,859.78\n",
      "   ‚Ä¢ Error relativo promedio: 33.79%\n",
      "   ‚Ä¢ Error relativo mediano: 39.84%\n",
      "\n",
      "üìà Percentiles de error absoluto en outliers:\n",
      "   ‚Ä¢ P25: $32,562\n",
      "   ‚Ä¢ P50: $35,860\n",
      "   ‚Ä¢ P75: $71,973\n",
      "   ‚Ä¢ P90: $93,641\n",
      "\n",
      "üí° RECOMENDACIONES PARA MEJORAR EL MODELO\n",
      "============================================================\n",
      "\n",
      "üìâ El modelo tiende a SUBESTIMAR salarios altos:\n",
      "   ‚Ä¢ Revisar feature engineering para capturar mejor salarios premium\n",
      "   ‚Ä¢ Considerar transformaci√≥n logar√≠tmica\n",
      "   ‚Ä¢ Ajustar regularizaci√≥n para permitir predicciones m√°s altas\n",
      "\n",
      "‚úÖ PR√ìXIMOS PASOS:\n",
      "1. Exportar √≠ndices de outliers para an√°lisis manual\n",
      "2. Verificar datos originales de casos extremos\n",
      "3. Implementar mejoras espec√≠ficas identificadas\n",
      "4. Re-evaluar modelo sin outliers extremos\n",
      "\n",
      "üíæ DATOS DE OUTLIERS PARA EXPORTAR:\n",
      "============================================================\n",
      "# C√≥digo para exportar outliers:\n",
      "outliers_to_export = outliers_df.copy()\n",
      "# outliers_to_export.to_csv('outliers_analysis.csv', index=False)\n",
      "# Total registros a exportar: 3\n"
     ]
    }
   ],
   "source": [
    "# AN√ÅLISIS DE OUTLIERS USANDO SOLO MODEL_RESULTS\n",
    "print(\"üîç AN√ÅLISIS DE OUTLIERS CON MODEL_RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. EXTRAER DATOS DESDE MODEL_RESULTS\n",
    "model_results = results['model_results']['LightGBM_Optuna']\n",
    "y_test = results['y_test']\n",
    "y_pred = model_results['predictions']\n",
    "\n",
    "print(f\"üìä Datos disponibles:\")\n",
    "print(f\"   ‚Ä¢ Predicciones: {len(y_pred)} casos\")\n",
    "print(f\"   ‚Ä¢ Valores reales: {len(y_test)} casos\")\n",
    "\n",
    "# 2. CALCULAR ERRORES Y IDENTIFICAR OUTLIERS\n",
    "residuos = y_test - y_pred\n",
    "abs_errors = np.abs(residuos)\n",
    "rel_errors = (abs_errors / y_test) * 100\n",
    "\n",
    "# Convertir a arrays numpy para evitar problemas de indexing\n",
    "y_test_array = y_test.values if hasattr(y_test, 'values') else np.array(y_test)\n",
    "y_pred_array = np.array(y_pred)\n",
    "abs_errors_array = np.abs(y_test_array - y_pred_array)\n",
    "rel_errors_array = (abs_errors_array / y_test_array) * 100\n",
    "\n",
    "# Threshold para outliers (2 std)\n",
    "threshold = 2 * np.std(abs_errors_array)\n",
    "outliers_mask = abs_errors_array > threshold\n",
    "outliers_indices = np.where(outliers_mask)[0]\n",
    "\n",
    "print(f\"\\nüéØ DETECCI√ìN DE OUTLIERS:\")\n",
    "print(f\"   ‚Ä¢ Threshold: ${threshold:,.2f}\")\n",
    "print(f\"   ‚Ä¢ Outliers encontrados: {len(outliers_indices)} casos\")\n",
    "print(f\"   ‚Ä¢ Porcentaje: {(len(outliers_indices)/len(y_test))*100:.2f}%\")\n",
    "\n",
    "# 3. AN√ÅLISIS DETALLADO DE OUTLIERS\n",
    "print(f\"\\nüî¥ TOP 15 OUTLIERS M√ÅS PROBLEM√ÅTICOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Crear DataFrame con la informaci√≥n de outliers\n",
    "outliers_df = pd.DataFrame({\n",
    "    'Index': outliers_indices,\n",
    "    'Salary_Real': y_test_array[outliers_indices],\n",
    "    'Salary_Pred': y_pred_array[outliers_indices],\n",
    "    'Error_Abs': abs_errors_array[outliers_indices],\n",
    "    'Error_Rel': rel_errors_array[outliers_indices]\n",
    "})\n",
    "\n",
    "# Ordenar por error absoluto (descendente)\n",
    "outliers_df = outliers_df.sort_values('Error_Abs', ascending=False)\n",
    "\n",
    "print(\"Rank  Index   Salario Real   Predicci√≥n    Error Abs    Error %\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "for i, (_, row) in enumerate(outliers_df.head(15).iterrows(), 1):\n",
    "    print(f\"{i:2d}    {row['Index']:4.0f}   ${row['Salary_Real']:9.0f}   ${row['Salary_Pred']:9.0f}   ${row['Error_Abs']:8.0f}   {row['Error_Rel']:6.1f}%\")\n",
    "\n",
    "# 4. ESTAD√çSTICAS DE OUTLIERS vs NORMALES\n",
    "print(f\"\\nüìà COMPARACI√ìN: OUTLIERS vs CASOS NORMALES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "normal_mask = ~outliers_mask\n",
    "\n",
    "# Salarios reales\n",
    "outlier_salaries = y_test_array[outliers_mask]\n",
    "normal_salaries = y_test_array[normal_mask]\n",
    "\n",
    "print(\"M√©trica                 Outliers      Normales    Diferencia\")\n",
    "print(\"-\" * 65)\n",
    "print(f\"{'Media Salario':20s}   ${outlier_salaries.mean():9.0f} ${normal_salaries.mean():9.0f}   ${outlier_salaries.mean() - normal_salaries.mean():+9.0f}\")\n",
    "#print(f\"{'Mediana Salario':20s}   ${outlier_salaries.median():9.0f} ${normal_salaries.median():9.0f}   ${outlier_salaries.median() - normal_salaries.median():+9.0f}\")\n",
    "print(f\"{'Std Salario':20s}   ${outlier_salaries.std():9.0f} ${normal_salaries.std():9.0f}   ${outlier_salaries.std() - normal_salaries.std():+9.0f}\")\n",
    "\n",
    "# Errores\n",
    "outlier_errors = abs_errors_array[outliers_mask]\n",
    "normal_errors = abs_errors_array[normal_mask]\n",
    "\n",
    "print(f\"{'Error Promedio':20s}   ${outlier_errors.mean():9.0f} ${normal_errors.mean():9.0f}   ${outlier_errors.mean() - normal_errors.mean():+9.0f}\")\n",
    "print(f\"{'Error Mediano':20s}   ${np.median(outlier_errors):9.0f} ${np.median(normal_errors):9.0f}   ${np.median(outlier_errors) - np.median(normal_errors):+9.0f}\")\n",
    "\n",
    "# 5. AN√ÅLISIS DE DISTRIBUCI√ìN DE OUTLIERS\n",
    "print(f\"\\nüìä DISTRIBUCI√ìN DE OUTLIERS POR RANGOS SALARIALES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Definir rangos salariales\n",
    "salary_ranges = [\n",
    "    (0, 50000, \"Bajo (<$50K)\"),\n",
    "    (50000, 100000, \"Medio ($50K-$100K)\"),\n",
    "    (100000, 150000, \"Alto ($100K-$150K)\"),\n",
    "    (150000, 200000, \"Muy Alto ($150K-$200K)\"),\n",
    "    (200000, float('inf'), \"Premium (>$200K)\")\n",
    "]\n",
    "\n",
    "print(\"Rango Salarial        Total    Outliers   Tasa Outlier\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for min_sal, max_sal, label in salary_ranges:\n",
    "    # Casos en este rango\n",
    "    in_range = (y_test_array >= min_sal) & (y_test_array < max_sal)\n",
    "    total_in_range = in_range.sum()\n",
    "    \n",
    "    if total_in_range > 0:\n",
    "        # Outliers en este rango\n",
    "        outliers_in_range = (in_range & outliers_mask).sum()\n",
    "        outlier_rate = (outliers_in_range / total_in_range) * 100\n",
    "        \n",
    "        print(f\"{label:20s}   {total_in_range:5d}    {outliers_in_range:8d}   {outlier_rate:8.2f}%\")\n",
    "\n",
    "# 6. AN√ÅLISIS DE PATRONES EN PREDICCIONES\n",
    "print(f\"\\nüéØ PATRONES EN LAS PREDICCIONES ERR√ìNEAS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Casos donde el modelo subestima mucho\n",
    "underestimated = outliers_df[outliers_df['Salary_Real'] > outliers_df['Salary_Pred']]\n",
    "underestimated_severe = underestimated[underestimated['Error_Rel'] > 30]\n",
    "\n",
    "# Casos donde el modelo sobreestima mucho\n",
    "overestimated = outliers_df[outliers_df['Salary_Real'] < outliers_df['Salary_Pred']]\n",
    "overestimated_severe = overestimated[overestimated['Error_Rel'] > 30]\n",
    "\n",
    "print(f\"üìâ Subestimaciones severas (>30%): {len(underestimated_severe)} casos\")\n",
    "if len(underestimated_severe) > 0:\n",
    "    print(f\"   ‚Ä¢ Error promedio: ${underestimated_severe['Error_Abs'].mean():,.0f}\")\n",
    "    print(f\"   ‚Ä¢ Salario real promedio: ${underestimated_severe['Salary_Real'].mean():,.0f}\")\n",
    "    print(f\"   ‚Ä¢ Predicci√≥n promedio: ${underestimated_severe['Salary_Pred'].mean():,.0f}\")\n",
    "\n",
    "print(f\"\\nüìà Sobreestimaciones severas (>30%): {len(overestimated_severe)} casos\")\n",
    "if len(overestimated_severe) > 0:\n",
    "    print(f\"   ‚Ä¢ Error promedio: ${overestimated_severe['Error_Abs'].mean():,.0f}\")\n",
    "    print(f\"   ‚Ä¢ Salario real promedio: ${overestimated_severe['Salary_Real'].mean():,.0f}\")\n",
    "    print(f\"   ‚Ä¢ Predicci√≥n promedio: ${overestimated_severe['Salary_Pred'].mean():,.0f}\")\n",
    "\n",
    "# 7. CASOS EXTREMOS PARA INVESTIGACI√ìN MANUAL\n",
    "print(f\"\\nüîç CASOS EXTREMOS PARA INVESTIGACI√ìN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Casos con errores relativos extremos\n",
    "extreme_cases = outliers_df[outliers_df['Error_Rel'] > 50]\n",
    "print(f\"‚ö†Ô∏è  Casos con error relativo >50%: {len(extreme_cases)}\")\n",
    "\n",
    "if len(extreme_cases) > 0:\n",
    "    print(\"\\nCasos que requieren investigaci√≥n manual:\")\n",
    "    for _, row in extreme_cases.head(5).iterrows():\n",
    "        error_type = \"Subestim√≥\" if row['Salary_Real'] > row['Salary_Pred'] else \"Sobreestim√≥\"\n",
    "        print(f\"  ‚Ä¢ √çndice {row['Index']:.0f}: {error_type}\")\n",
    "        print(f\"    Real: ${row['Salary_Real']:,.0f} | Pred: ${row['Salary_Pred']:,.0f} | Error: {row['Error_Rel']:.1f}%\")\n",
    "\n",
    "# 8. M√âTRICAS DE OUTLIERS\n",
    "print(f\"\\nüìä M√âTRICAS ESPEC√çFICAS DE OUTLIERS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"üéØ Estad√≠sticas de errores en outliers:\")\n",
    "print(f\"   ‚Ä¢ Error absoluto promedio: ${outliers_df['Error_Abs'].mean():,.2f}\")\n",
    "print(f\"   ‚Ä¢ Error absoluto mediano: ${outliers_df['Error_Abs'].median():,.2f}\")\n",
    "print(f\"   ‚Ä¢ Error relativo promedio: {outliers_df['Error_Rel'].mean():.2f}%\")\n",
    "print(f\"   ‚Ä¢ Error relativo mediano: {outliers_df['Error_Rel'].median():.2f}%\")\n",
    "\n",
    "# Percentiles de errores en outliers\n",
    "print(f\"\\nüìà Percentiles de error absoluto en outliers:\")\n",
    "print(f\"   ‚Ä¢ P25: ${np.percentile(outliers_df['Error_Abs'], 25):,.0f}\")\n",
    "print(f\"   ‚Ä¢ P50: ${np.percentile(outliers_df['Error_Abs'], 50):,.0f}\")\n",
    "print(f\"   ‚Ä¢ P75: ${np.percentile(outliers_df['Error_Abs'], 75):,.0f}\")\n",
    "print(f\"   ‚Ä¢ P90: ${np.percentile(outliers_df['Error_Abs'], 90):,.0f}\")\n",
    "\n",
    "# 9. RECOMENDACIONES BASADAS EN EL AN√ÅLISIS\n",
    "print(f\"\\nüí° RECOMENDACIONES PARA MEJORAR EL MODELO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if len(extreme_cases) > 0:\n",
    "    print(\"üî¥ PRIORIDAD ALTA:\")\n",
    "    print(f\"   ‚Ä¢ Investigar {len(extreme_cases)} casos con error >50%\")\n",
    "    print(\"   ‚Ä¢ Verificar posibles errores en los datos\")\n",
    "    print(\"   ‚Ä¢ Considerar exclusi√≥n temporal para validar\")\n",
    "\n",
    "if len(underestimated_severe) > len(overestimated_severe):\n",
    "    print(f\"\\nüìâ El modelo tiende a SUBESTIMAR salarios altos:\")\n",
    "    print(\"   ‚Ä¢ Revisar feature engineering para capturar mejor salarios premium\")\n",
    "    print(\"   ‚Ä¢ Considerar transformaci√≥n logar√≠tmica\")\n",
    "    print(\"   ‚Ä¢ Ajustar regularizaci√≥n para permitir predicciones m√°s altas\")\n",
    "elif len(overestimated_severe) > len(underestimated_severe):\n",
    "    print(f\"\\nüìà El modelo tiende a SOBREESTIMAR:\")\n",
    "    print(\"   ‚Ä¢ Aumentar regularizaci√≥n\")\n",
    "    print(\"   ‚Ä¢ Revisar outliers en datos de entrenamiento\")\n",
    "\n",
    "outlier_rate = (len(outliers_indices)/len(y_test))*100\n",
    "if outlier_rate > 10:\n",
    "    print(f\"\\n‚ö†Ô∏è  Tasa de outliers alta ({outlier_rate:.2f}%):\")\n",
    "    print(\"   ‚Ä¢ Revisar calidad de los datos\")\n",
    "    print(\"   ‚Ä¢ Considerar ensemble de modelos\")\n",
    "    print(\"   ‚Ä¢ Implementar detecci√≥n de anomal√≠as en preprocessing\")\n",
    "\n",
    "print(f\"\\n‚úÖ PR√ìXIMOS PASOS:\")\n",
    "print(\"1. Exportar √≠ndices de outliers para an√°lisis manual\")\n",
    "print(\"2. Verificar datos originales de casos extremos\")\n",
    "print(\"3. Implementar mejoras espec√≠ficas identificadas\")\n",
    "print(\"4. Re-evaluar modelo sin outliers extremos\")\n",
    "\n",
    "# 10. EXPORTAR OUTLIERS PARA AN√ÅLISIS\n",
    "print(f\"\\nüíæ DATOS DE OUTLIERS PARA EXPORTAR:\")\n",
    "print(\"=\"*60)\n",
    "print(\"# C√≥digo para exportar outliers:\")\n",
    "print(\"outliers_to_export = outliers_df.copy()\")\n",
    "print(\"# outliers_to_export.to_csv('outliers_analysis.csv', index=False)\")\n",
    "print(f\"# Total registros a exportar: {len(outliers_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050e11cd",
   "metadata": {},
   "source": [
    "****************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3103a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\x80\\x04\\x95\\xf3\\x01\\x00\\x00\\x00\\x00\\x00\\x00}\\x94(\\x8c\\x05model\\x94\\x8c\\x10lightgbm.sklearn\\x94\\x8c\\rLGBMReg'\n"
     ]
    }
   ],
   "source": [
    "with open(\"../../../modelos/salary_with_stats.pkl\", \"rb\") as f:\n",
    "    print(f.read(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73330837",
   "metadata": {},
   "source": [
    "Pr√≥ximos pasos:\n",
    "    Probar un ensamble de modelos\n",
    "    Implementar monitoreo de drift\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e919b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b62fb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf=data[(data['Salary'] < 90000) & (data['Salary'] > 35000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd497940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Years_of_Experience</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Description</th>\n",
       "      <th>Exp_group</th>\n",
       "      <th>Age_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Master's</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>3.0</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>I am a 28-year-old data analyst with a Master'...</td>\n",
       "      <td>Junior</td>\n",
       "      <td>Joven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Sales Associate</td>\n",
       "      <td>7.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>I am a 36-year-old female Sales Associate with...</td>\n",
       "      <td>Medio</td>\n",
       "      <td>Medio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Marketing Analyst</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>I am a 29-year-old Marketing Analyst with a Ba...</td>\n",
       "      <td>Junior</td>\n",
       "      <td>Joven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Sales Manager</td>\n",
       "      <td>4.0</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>I am a 31-year-old Sales Manager with a Bachel...</td>\n",
       "      <td>Junior</td>\n",
       "      <td>Medio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Marketing Coordinator</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>I am a 26-year-old female Marketing Coordinato...</td>\n",
       "      <td>Junior</td>\n",
       "      <td>Joven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>363</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Junior Marketing Specialist</td>\n",
       "      <td>5.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>I am a 33-year-old male with a Bachelor's degr...</td>\n",
       "      <td>Junior</td>\n",
       "      <td>Medio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>366</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Junior Financial Analyst</td>\n",
       "      <td>3.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>I am a 31-year-old female working as a Junior ...</td>\n",
       "      <td>Junior</td>\n",
       "      <td>Medio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>369</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Junior Business Analyst</td>\n",
       "      <td>4.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>I am a 33-year-old male working as a Junior Bu...</td>\n",
       "      <td>Junior</td>\n",
       "      <td>Medio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>370</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Senior Marketing Analyst</td>\n",
       "      <td>8.0</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>As a 35-year-old Senior Marketing Analyst with...</td>\n",
       "      <td>Medio</td>\n",
       "      <td>Medio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>372</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Junior Project Manager</td>\n",
       "      <td>2.0</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>As a 29-year-old female Junior Project Manager...</td>\n",
       "      <td>Junior</td>\n",
       "      <td>Joven</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141 rows √ó 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id   Age  Gender Education_Level                    Job_Title  \\\n",
       "1      1  28.0  Female        Master's                 Data Analyst   \n",
       "3      3  36.0  Female      Bachelor's              Sales Associate   \n",
       "5      5  29.0    Male      Bachelor's            Marketing Analyst   \n",
       "7      7  31.0    Male      Bachelor's                Sales Manager   \n",
       "8      8  26.0  Female      Bachelor's        Marketing Coordinator   \n",
       "..   ...   ...     ...             ...                          ...   \n",
       "361  363  33.0    Male      Bachelor's  Junior Marketing Specialist   \n",
       "364  366  31.0  Female      Bachelor's     Junior Financial Analyst   \n",
       "367  369  33.0    Male      Bachelor's      Junior Business Analyst   \n",
       "368  370  35.0  Female      Bachelor's     Senior Marketing Analyst   \n",
       "370  372  29.0  Female      Bachelor's       Junior Project Manager   \n",
       "\n",
       "     Years_of_Experience   Salary  \\\n",
       "1                    3.0  65000.0   \n",
       "3                    7.0  60000.0   \n",
       "5                    2.0  55000.0   \n",
       "7                    4.0  80000.0   \n",
       "8                    1.0  45000.0   \n",
       "..                   ...      ...   \n",
       "361                  5.0  70000.0   \n",
       "364                  3.0  50000.0   \n",
       "367                  4.0  60000.0   \n",
       "368                  8.0  85000.0   \n",
       "370                  2.0  40000.0   \n",
       "\n",
       "                                           Description Exp_group Age_group  \n",
       "1    I am a 28-year-old data analyst with a Master'...    Junior     Joven  \n",
       "3    I am a 36-year-old female Sales Associate with...     Medio     Medio  \n",
       "5    I am a 29-year-old Marketing Analyst with a Ba...    Junior     Joven  \n",
       "7    I am a 31-year-old Sales Manager with a Bachel...    Junior     Medio  \n",
       "8    I am a 26-year-old female Marketing Coordinato...    Junior     Joven  \n",
       "..                                                 ...       ...       ...  \n",
       "361  I am a 33-year-old male with a Bachelor's degr...    Junior     Medio  \n",
       "364  I am a 31-year-old female working as a Junior ...    Junior     Medio  \n",
       "367  I am a 33-year-old male working as a Junior Bu...    Junior     Medio  \n",
       "368  As a 35-year-old Senior Marketing Analyst with...     Medio     Medio  \n",
       "370  As a 29-year-old female Junior Project Manager...    Junior     Joven  \n",
       "\n",
       "[141 rows x 10 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
